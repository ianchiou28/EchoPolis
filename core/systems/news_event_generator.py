"""
æ–°é—»äº‹ä»¶ç”Ÿæˆå™¨ - åŸºäºçœŸå®æ–°é—»ç”Ÿæˆæ¸¸æˆäº‹ä»¶
ä» finai.org.cn/information çˆ¬å–é‡‘èæ–°é—»ï¼Œä½¿ç”¨ AI ç”Ÿæˆä¸ªæ€§åŒ–æ¸¸æˆäº‹ä»¶
æ”¯æŒæ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨äº‹ä»¶æ± 
"""
import re
import json
import time
import requests
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# Selenium å¯¼å…¥
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("[NewsGenerator] Selenium æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ•°æ®")

# å¯¼å…¥æ•°æ®åº“å’ŒAIæ¨¡å—
try:
    from core.database.news_event_db import news_event_db
except ImportError:
    news_event_db = None

try:
    from core.ai.deepseek_engine import deepseek_engine
except ImportError:
    deepseek_engine = None

@dataclass
class NewsItem:
    """æ–°é—»æ¡ç›®"""
    title: str
    title_cn: str  # ä¸­æ–‡æ ‡é¢˜
    summary: str
    source: str
    category: str  # macro/stock/crypto/policy/global/merger
    sentiment: str  # positive/negative/neutral
    timestamp: float
    news_id: str = ""
    
    def to_dict(self) -> Dict:
        return asdict(self)

@dataclass
class GeneratedEvent:
    """ç”Ÿæˆçš„æ¸¸æˆäº‹ä»¶"""
    id: str
    title: str
    description: str
    category: str
    tags: List[str]
    options: List[Dict]
    source_news: str
    ai_analysis: str
    match_score: float = 0.0
    news_id: str = ""
    
    def to_dict(self) -> Dict:
        return asdict(self)

class NewsEventGenerator:
    """æ–°é—»äº‹ä»¶ç”Ÿæˆå™¨ - ä» finai.org.cn è·å–å®æ—¶é‡‘èèµ„è®¯ï¼ŒAIç”Ÿæˆäº‹ä»¶å­˜å…¥æ•°æ®åº“"""
    
    def __init__(self):
        self.source_url = "http://www.finai.org.cn/information/"
        self.news_cache: List[NewsItem] = []
        self.generated_events: List[GeneratedEvent] = []
        self.last_fetch = 0
        self.cache_duration = 1800  # 30åˆ†é’Ÿç¼“å­˜
        self.market_sentiment = "neutral"
        self.hot_topics: List[str] = []
        self.db = news_event_db
        self.ai = deepseek_engine
        
    async def fetch_and_generate_events(self, user_tags: List[str] = None, force_refresh: bool = False) -> List[Dict]:
        """
        ä¸»å…¥å£ï¼šè·å–æ–°é—» -> AIç”Ÿæˆäº‹ä»¶ -> å­˜å…¥æ•°æ®åº“ -> è¿”å›äº‹ä»¶
        """
        # 1. å…ˆæ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰æ´»è·ƒäº‹ä»¶
        if self.db and not force_refresh:
            db_events = self.db.get_active_events(limit=20)
            if len(db_events) >= 5:
                print(f"[NewsGenerator] ä»æ•°æ®åº“è¿”å› {len(db_events)} æ¡äº‹ä»¶")
                return self._filter_by_tags(db_events, user_tags)
        
        # 2. çˆ¬å–æ–°é—»
        news_items = self.fetch_news()
        
        # 3. ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“
        if self.db and news_items:
            self.db.save_news_batch([n.to_dict() for n in news_items])
            # ä¿å­˜å¸‚åœºçŠ¶æ€
            self.db.save_market_status({
                'sentiment': self.market_sentiment,
                'hot_topics': self.hot_topics
            })
        
        # 4. AIç”Ÿæˆäº‹ä»¶
        events = await self._ai_generate_events(news_items, user_tags)
        
        # 5. ä¿å­˜äº‹ä»¶åˆ°æ•°æ®åº“
        if self.db and events:
            event_dicts = [e.to_dict() if isinstance(e, GeneratedEvent) else e for e in events]
            self.db.save_events_batch(event_dicts)
        
        # 6. æ¸…ç†è¿‡æœŸæ•°æ®
        if self.db:
            self.db.cleanup_expired()
        
        return [e.to_dict() if isinstance(e, GeneratedEvent) else e for e in events]
    
    async def _ai_generate_events(self, news_items: List[NewsItem], user_tags: List[str] = None) -> List[GeneratedEvent]:
        """ä½¿ç”¨AIåŸºäºæ–°é—»ç”Ÿæˆäº‹ä»¶"""
        events = []
        
        if not news_items:
            return events
        
        # å°è¯•ä½¿ç”¨AIç”Ÿæˆ
        if self.ai:
            try:
                ai_events = await self._generate_with_ai(news_items, user_tags)
                if ai_events:
                    events.extend(ai_events)
                    print(f"[NewsGenerator] AIç”Ÿæˆäº† {len(ai_events)} æ¡äº‹ä»¶")
                    return events
            except Exception as e:
                print(f"[NewsGenerator] AIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {e}")
        
        # å›é€€åˆ°æ¨¡æ¿ç”Ÿæˆ
        for i, news in enumerate(news_items[:10]):
            event = self._news_to_event(news, i, user_tags)
            if event:
                events.append(event)
        
        return events
    
    async def _generate_with_ai(self, news_items: List[NewsItem], user_tags: List[str] = None) -> List[GeneratedEvent]:
        """è°ƒç”¨DeepSeek AIç”Ÿæˆäº‹ä»¶"""
        if not self.ai:
            return []
        
        # æ„å»ºæ–°é—»æ‘˜è¦
        news_summary = "\n".join([
            f"- [{n.category}] {n.title_cn} (æƒ…ç»ª:{n.sentiment}, æ¥æº:{n.source})"
            for n in news_items[:8]
        ])
        
        user_context = f"ç”¨æˆ·å…³æ³¨æ ‡ç­¾: {', '.join(user_tags)}" if user_tags else "ç”¨æˆ·æš‚æ— ç‰¹å®šæ ‡ç­¾"
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªé‡‘èæ¸¸æˆäº‹ä»¶è®¾è®¡å¸ˆã€‚åŸºäºä»¥ä¸‹çœŸå®é‡‘èæ–°é—»ï¼Œä¸ºæ¸¸æˆç©å®¶ç”Ÿæˆ5-8ä¸ªæœ‰è¶£ä¸”æœ‰æ•™è‚²æ„ä¹‰çš„æŠ•èµ„å†³ç­–äº‹ä»¶ã€‚

ã€ä»Šæ—¥å¸‚åœºæƒ…ç»ªã€‘{self.market_sentiment}
ã€çƒ­é—¨è¯é¢˜ã€‘{', '.join(self.hot_topics[:5])}
ã€{user_context}ã€‘

ã€ä»Šæ—¥æ–°é—»ã€‘
{news_summary}

è¯·ä¸ºæ¯æ¡ç›¸å…³æ–°é—»ç”Ÿæˆä¸€ä¸ªæ¸¸æˆäº‹ä»¶ï¼Œæ ¼å¼å¦‚ä¸‹ï¼ˆJSONæ•°ç»„ï¼‰ï¼š
[
  {{
    "title": "äº‹ä»¶æ ‡é¢˜ï¼ˆå¸¦emojiï¼Œå¦‚ï¼šğŸ“ˆ ç§‘æŠ€è‚¡æš´æ¶¨ï¼‰",
    "description": "åŸºäºæ–°é—»çš„è¯¦ç»†æè¿°ï¼Œè¯´æ˜å¯¹ç©å®¶çš„å½±å“å’Œé€‰æ‹©èƒŒæ™¯",
    "category": "stock/crypto/policy/tech/merger/global/macroä¹‹ä¸€",
    "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"],
    "source_news": "å¯¹åº”çš„æ–°é—»æ ‡é¢˜",
    "ai_analysis": "AIå¯¹è¿™æ¡æ–°é—»çš„ç®€çŸ­åˆ†æå’ŒæŠ•èµ„å»ºè®®",
    "options": [
      {{"text": "é€‰é¡¹1æè¿°", "tags": ["action_tag"], "effects": {{"cash": æ•°å€¼å˜åŒ–, "happiness": æ•°å€¼å˜åŒ–}}}},
      {{"text": "é€‰é¡¹2æè¿°", "tags": ["action_tag"], "effects": {{}}}},
      {{"text": "é€‰é¡¹3æè¿°", "tags": ["action_tag"], "effects": {{"cash": æ•°å€¼å˜åŒ–}}}}
    ]
  }}
]

è¦æ±‚ï¼š
1. æ¯ä¸ªäº‹ä»¶æœ‰3ä¸ªé€‰æ‹©ï¼Œä½“ç°ä¸åŒæŠ•èµ„é£æ ¼ï¼ˆä¿å®ˆ/ç¨³å¥/æ¿€è¿›ï¼‰
2. effectsä¸­çš„cashç”¨æ•´æ•°è¡¨ç¤ºé‡‘é¢å˜åŒ–ï¼Œhappinessè¡¨ç¤ºå¿ƒæƒ…å˜åŒ–
3. é€‰é¡¹è¦æœ‰çœŸå®æ„Ÿå’Œæ•™è‚²æ„ä¹‰
4. åŸºäºçœŸå®æ–°é—»ä½†é€‚å½“æ¸¸æˆåŒ–
5. åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹"""

        try:
            response = await self.ai.generate_async(prompt, max_tokens=3000)
            
            # è§£æJSON
            json_match = re.search(r'\[[\s\S]*\]', response)
            if json_match:
                events_data = json.loads(json_match.group())
                events = []
                for i, data in enumerate(events_data):
                    event = GeneratedEvent(
                        id=f"ai_news_{int(time.time())}_{i}",
                        title=data.get('title', ''),
                        description=data.get('description', ''),
                        category=data.get('category', 'macro'),
                        tags=data.get('tags', []),
                        options=data.get('options', []),
                        source_news=data.get('source_news', ''),
                        ai_analysis=data.get('ai_analysis', ''),
                        match_score=0.8,  # AIç”Ÿæˆçš„äº‹ä»¶ç»™äºˆè¾ƒé«˜åŒ¹é…åº¦
                        news_id=f"news_{int(time.time())}_{i}"
                    )
                    events.append(event)
                return events
        except Exception as e:
            print(f"[NewsGenerator] AIè§£æå¤±è´¥: {e}")
        
        return []
    
    def _filter_by_tags(self, events: List[Dict], user_tags: List[str] = None) -> List[Dict]:
        """æ ¹æ®ç”¨æˆ·æ ‡ç­¾ç­›é€‰å’Œæ’åºäº‹ä»¶"""
        if not user_tags:
            return events
        
        for event in events:
            event_tags = event.get('tags', [])
            match_count = len(set(user_tags) & set(event_tags))
            event['match_score'] = event.get('match_score', 0.5) + match_count * 0.1
        
        events.sort(key=lambda x: x.get('match_score', 0), reverse=True)
        return events
    
    def _fetch_with_selenium(self) -> str:
        """ä½¿ç”¨ Selenium çˆ¬å– SPA é¡µé¢"""
        if not SELENIUM_AVAILABLE:
            print("[NewsGenerator] Selenium ä¸å¯ç”¨")
            return ""
        
        driver = None
        try:
            print("[NewsGenerator] å¯åŠ¨ Chrome æµè§ˆå™¨...")
            
            # Chrome é€‰é¡¹
            chrome_options = Options()
            chrome_options.add_argument("--headless")  # æ— å¤´æ¨¡å¼
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            
            # è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç† ChromeDriver
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            print(f"[NewsGenerator] è®¿é—® {self.source_url}")
            driver.get(self.source_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆç­‰å¾…æŸä¸ªå…ƒç´ å‡ºç°ï¼‰
            print("[NewsGenerator] ç­‰å¾…é¡µé¢åŠ è½½...")
            WebDriverWait(driver, 15).until(
                lambda d: len(d.page_source) > 2000
            )
            
            # é¢å¤–ç­‰å¾… JavaScript æ¸²æŸ“
            time.sleep(3)
            
            content = driver.page_source
            print(f"[NewsGenerator] è·å–åˆ°é¡µé¢å†…å®¹ï¼Œé•¿åº¦: {len(content)}")
            
            return content
            
        except Exception as e:
            print(f"[NewsGenerator] Selenium çˆ¬å–å¤±è´¥: {e}")
            return ""
        finally:
            if driver:
                driver.quit()
        
    def fetch_news(self) -> List[NewsItem]:
        """ä» finai.org.cn/information çˆ¬å–æ–°é—»"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if self.news_cache and (current_time - self.last_fetch < self.cache_duration):
            print(f"[NewsGenerator] ä½¿ç”¨ç¼“å­˜æ•°æ® ({len(self.news_cache)} æ¡)")
            return self.news_cache
        
        # ä½¿ç”¨ Selenium çˆ¬å– SPA é¡µé¢
        content = self._fetch_with_selenium()
        
        if content and len(content) > 2000:
            news_items = self._parse_finai_page(content)
            if news_items:
                self.news_cache = news_items
                self.last_fetch = current_time
                print(f"[NewsGenerator] æˆåŠŸä» finai.org.cn è·å– {len(news_items)} æ¡æ–°é—»")
                return news_items
        
        print("[NewsGenerator] çˆ¬å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®")
        return self._get_fallback_news()
    
    def sync_fetch_and_generate(self, user_tags: List[str] = None, force_refresh: bool = False) -> List[Dict]:
        """åŒæ­¥ç‰ˆæœ¬çš„è·å–å’Œç”Ÿæˆæ–¹æ³• - ä¸ä½¿ç”¨AIï¼Œç›´æ¥ç”¨æ¨¡æ¿ç”Ÿæˆ"""
        # 1. å…ˆæ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰æ´»è·ƒäº‹ä»¶
        if self.db and not force_refresh:
            db_events = self.db.get_active_events(limit=20)
            if len(db_events) >= 5:
                print(f"[NewsGenerator] ä»æ•°æ®åº“è¿”å› {len(db_events)} æ¡äº‹ä»¶")
                return self._filter_by_tags(db_events, user_tags)
        
        # 2. çˆ¬å–æ–°é—»
        news_items = self.fetch_news()
        
        # 3. ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“
        if self.db and news_items:
            self.db.save_news_batch([n.to_dict() for n in news_items])
            self.db.save_market_status({
                'sentiment': self.market_sentiment,
                'hot_topics': self.hot_topics
            })
        
        # 4. ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆäº‹ä»¶ï¼ˆåŒæ­¥ï¼Œä¸ç”¨AIï¼‰
        events = []
        for i, news in enumerate(news_items[:10]):
            event = self._news_to_event(news, i, user_tags)
            if event:
                events.append(event)
        
        # 5. ä¿å­˜äº‹ä»¶åˆ°æ•°æ®åº“
        if self.db and events:
            event_dicts = [e.to_dict() if isinstance(e, GeneratedEvent) else e for e in events]
            self.db.save_events_batch(event_dicts)
        
        # 6. æ¸…ç†è¿‡æœŸæ•°æ®
        if self.db:
            self.db.cleanup_expired()
        
        result = [e.to_dict() if isinstance(e, GeneratedEvent) else e for e in events]
        print(f"[NewsGenerator] åŒæ­¥ç”Ÿæˆäº† {len(result)} æ¡äº‹ä»¶")
        return result
    
    def _parse_finai_page(self, content: str) -> List[NewsItem]:
        """è§£æ finai.org.cn/information é¡µé¢å†…å®¹"""
        news_items = []
        
        # æ¸…ç† HTML æ ‡ç­¾çš„è¾…åŠ©å‡½æ•°
        def clean_html(text):
            # ç§»é™¤æ‰€æœ‰ HTML æ ‡ç­¾
            text = re.sub(r'<[^>]+>', '', text)
            # ç§»é™¤ data-v-xxx ç­‰ Vue å±æ€§æ®‹ç•™
            text = re.sub(r'data-v-[a-f0-9]+', '', text)
            # ç§»é™¤å¤šä½™ç©ºç™½
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        
        # 1. æå–å¸‚åœºæƒ…ç»ª
        sentiment_match = re.search(r'å¸‚åœºæƒ…ç»ª[ï¼š:\s]*(ç§¯æ|æ¶ˆæ|ä¸­æ€§)', content)
        if sentiment_match:
            self.market_sentiment = sentiment_match.group(1)
            print(f"[NewsGenerator] å¸‚åœºæƒ…ç»ª: {self.market_sentiment}")
        
        # 2. æå–çƒ­é—¨è¯é¢˜ - åŒ¹é… "è¯é¢˜Ã—æ•°å­—" æ ¼å¼
        topic_matches = re.findall(r'([A-Za-z\u4e00-\u9fa5]{2,15})Ã—(\d+)', content)
        if topic_matches:
            # æŒ‰å‡ºç°æ¬¡æ•°æ’åº
            sorted_topics = sorted(topic_matches, key=lambda x: int(x[1]), reverse=True)
            self.hot_topics = [t[0].strip() for t in sorted_topics[:10]]
            print(f"[NewsGenerator] çƒ­é—¨è¯é¢˜: {self.hot_topics}")
        
        # 3. æå–æ–°é—»é¡¹ - å¤šç§æ¨¡å¼åŒ¹é…
        
        # æ¨¡å¼1: åŒ¹é… "æ¥æº ç±»åˆ« æ ‡é¢˜â†’" æ ¼å¼
        pattern1 = r'(CNBC|Financial Times|Forbes|MarketWatch|é›ªçƒ|Bloomberg|Reuters|WSJ)[^â†’]*?(è´¢æŠ¥|å¹¶è´­|æ”¿ç­–|å…¶ä»–|å®è§‚|ç§‘æŠ€)[^â†’]*?([A-Za-z][^â†’]{10,100}?)([\u4e00-\u9fa5][^â†’<]{10,80}?)(?:â†’|<)'
        
        for match in re.finditer(pattern1, content):
            source = match.group(1).strip()
            category = match.group(2).strip()
            title_en = clean_html(match.group(3))
            title_cn = clean_html(match.group(4))
            
            if len(title_cn) > 8 and len(title_cn) < 100:
                news_items.append(self._create_news_item(
                    title_en, title_cn, source, category, len(news_items)
                ))
        
        # æ¨¡å¼2: ç›´æ¥åŒ¹é…ä¸­æ–‡æ–°é—»æ ‡é¢˜ï¼ˆåŒ…å«å…³é”®è¯ï¼‰
        if len(news_items) < 5:
            # æŸ¥æ‰¾å¯èƒ½çš„æ–°é—»æ ‡é¢˜åŒºåŸŸ
            cn_titles = re.findall(
                r'([\u4e00-\u9fa5]{2,8}(?:è‚¡|æ¶¨|è·Œ|æš´|åˆ›|ç ´|çªç ´|æ¿€å¢|ä¸‹è·Œ|ä¸Šæ¶¨|æ”¶è´­|å¹¶è´­|å‘å¸ƒ|æ¨å‡º)[\u4e00-\u9fa5ï¼Œã€\d%]{5,50})',
                content
            )
            for idx, title in enumerate(cn_titles[:15]):
                title = clean_html(title)
                # æ’é™¤å¤ªçŸ­æˆ–å·²å­˜åœ¨çš„
                if len(title) > 10 and not any(title in n.title_cn for n in news_items):
                    news_items.append(self._create_news_item(
                        title, title, "finai.org.cn", "å®è§‚", len(news_items)
                    ))
        
        # æ¨¡å¼3: åŒ¹é…è‹±æ–‡æ ‡é¢˜åè·Ÿä¸­æ–‡ç¿»è¯‘
        if len(news_items) < 5:
            pattern3 = r'([A-Z][a-zA-Z\s\',\.\$\d%]{15,80})\s*([\u4e00-\u9fa5][\u4e00-\u9fa5ï¼Œã€\d%]{10,60})'
            for match in re.finditer(pattern3, content):
                title_en = clean_html(match.group(1))
                title_cn = clean_html(match.group(2))
                
                if (len(title_cn) > 10 and len(title_cn) < 80 and 
                    not any(title_cn in n.title_cn for n in news_items)):
                    news_items.append(self._create_news_item(
                        title_en, title_cn, "finai.org.cn", "å®è§‚", len(news_items)
                    ))
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        seen = set()
        unique_items = []
        for item in news_items:
            # æ ‡å‡†åŒ–æ ‡é¢˜ç”¨äºå»é‡
            key = item.title_cn[:20]
            if key not in seen:
                seen.add(key)
                unique_items.append(item)
        
        return unique_items[:15]
    
    def _create_news_item(self, title_en: str, title_cn: str, source: str, category: str, idx: int) -> NewsItem:
        """åˆ›å»ºæ–°é—»æ¡ç›®"""
        news_category = self._map_category(category, title_cn)
        sentiment = self._analyze_sentiment(title_cn)
        news_id = f"news_{int(time.time()*1000)}_{idx}"
        
        return NewsItem(
            title=title_en[:100] if title_en else title_cn[:100],
            title_cn=title_cn[:100],
            summary=title_cn[:200],
            source=source,
            category=news_category,
            sentiment=sentiment,
            timestamp=time.time(),
            news_id=news_id
        )
    
    def _map_category(self, source_category: str, title: str) -> str:
        """æ˜ å°„æ–°é—»ç±»åˆ«"""
        category_map = {
            'è´¢æŠ¥': 'stock',
            'å¹¶è´­': 'merger',
            'æ”¿ç­–': 'policy',
            'å®è§‚': 'macro',
            'ç§‘æŠ€': 'tech',
            'å…¶ä»–': 'global'
        }
        
        # å…ˆç”¨æ¥æºåˆ†ç±»
        if source_category in category_map:
            return category_map[source_category]
        
        # å†æ ¹æ®å†…å®¹åˆ¤æ–­
        return self._categorize_news(title)
    
    def _categorize_news(self, text: str) -> str:
        """åˆ†ç±»æ–°é—»"""
        if any(k in text for k in ['ç¾è”å‚¨', 'å¤®è¡Œ', 'åˆ©ç‡', 'æ”¿ç­–', 'ç›‘ç®¡', 'Fed', 'Federal Reserve']):
            return 'policy'
        elif any(k in text for k in ['æ¯”ç‰¹å¸', 'åŠ å¯†', 'æ•°å­—è´§å¸', 'BTC', 'crypto', 'Bitcoin']):
            return 'crypto'
        elif any(k in text for k in ['ç¾è‚¡', 'Aè‚¡', 'æ¸¯è‚¡', 'è‚¡å¸‚', 'æŒ‡æ•°', 'æš´æ¶¨', 'æš´è·Œ', 'S&P', 'Nasdaq']):
            return 'stock'
        elif any(k in text for k in ['æ”¶è´­', 'å¹¶è´­', 'åˆå¹¶', 'merger', 'acquisition']):
            return 'merger'
        elif any(k in text for k in ['AI', 'äººå·¥æ™ºèƒ½', 'Nvidia', 'è‹±ä¼Ÿè¾¾', 'GPU', 'OpenAI']):
            return 'tech'
        elif any(k in text for k in ['å…¨çƒ', 'å›½é™…', 'è´¸æ˜“', 'åœ°ç¼˜', 'æ¬§æ´²', 'äºšæ´²']):
            return 'global'
        else:
            return 'macro'
    
    def _analyze_sentiment(self, text: str) -> str:
        """ç®€å•æƒ…æ„Ÿåˆ†æ"""
        positive_words = ['ä¸Šæ¶¨', 'å¢é•¿', 'çªç ´', 'æ–°é«˜', 'åˆ©å¥½', 'åå¼¹', 'å›æš–', 'æ¿€å¢', 'æš´æ¶¨', 'çœ‹æ¶¨', 
                         'surge', 'jump', 'soar', 'rise', 'gain', 'positive']
        negative_words = ['ä¸‹è·Œ', 'æš´è·Œ', 'ä¸‹æ»‘', 'å±æœº', 'åˆ©ç©º', 'å´©ç›˜', 'ææ…Œ', 'æ‹…å¿§', 'ä¸‹æŒ«',
                         'fall', 'drop', 'crash', 'decline', 'negative', 'fear']
        
        text_lower = text.lower()
        pos_count = sum(1 for w in positive_words if w in text or w in text_lower)
        neg_count = sum(1 for w in negative_words if w in text or w in text_lower)
        
        if pos_count > neg_count:
            return 'positive'
        elif neg_count > pos_count:
            return 'negative'
        return 'neutral'
    
    def _get_fallback_news(self) -> List[NewsItem]:
        """è·å–å¤‡ç”¨æ–°é—»ï¼ˆåŸºäºçƒ­é—¨è¯é¢˜ç”Ÿæˆï¼‰"""
        fallback = [
            NewsItem("AIèŠ¯ç‰‡éœ€æ±‚æŒç»­å¢é•¿", "AIèŠ¯ç‰‡éœ€æ±‚æŒç»­å¢é•¿ï¼Œç§‘æŠ€è‚¡å—ç›Š", "è‹±ä¼Ÿè¾¾ç­‰AIèŠ¯ç‰‡è‚¡æŒç»­èµ°å¼º", "system", "tech", "positive", time.time(), "fallback_1"),
            NewsItem("ç¾è”å‚¨æ”¿ç­–åŠ¨å‘", "å¸‚åœºå…³æ³¨ç¾è”å‚¨ä¸‹ä¸€æ­¥åˆ©ç‡å†³ç­–", "ç¾è”å‚¨æ”¿ç­–åŠ¨å‘å½±å“å…¨çƒå¸‚åœº", "system", "policy", "neutral", time.time(), "fallback_2"),
            NewsItem("ç§‘æŠ€å·¨å¤´è´¢æŠ¥å­£", "ç§‘æŠ€å·¨å¤´è´¢æŠ¥è¶…é¢„æœŸï¼Œæ¨åŠ¨å¸‚åœºä¸Šæ¶¨", "ç§‘æŠ€è‚¡è´¢æŠ¥è¡¨ç°äº®çœ¼", "system", "stock", "positive", time.time(), "fallback_3"),
            NewsItem("ä¸­å›½å¸‚åœºè¡¨ç°", "Aè‚¡å¸‚åœºéœ‡è¡æ•´ç†ï¼Œç­‰å¾…æ–¹å‘", "ä¸­å›½å¸‚åœºè§‚æœ›æƒ…ç»ªæµ“åš", "system", "macro", "neutral", time.time(), "fallback_4"),
            NewsItem("å…¨çƒç»æµå±•æœ›", "å…¨çƒç»æµå¤è‹åŠ¿å¤´å»¶ç»­", "ä¸»è¦ç»æµä½“å¢é•¿åŠ¨èƒ½æŒç»­", "system", "global", "positive", time.time(), "fallback_5"),
        ]
        return fallback
    
    def generate_events_from_news(self, user_tags: List[str] = None) -> List[GeneratedEvent]:
        """åŸºäºæ–°é—»ç”Ÿæˆæ¸¸æˆäº‹ä»¶"""
        news_items = self.fetch_news()
        events = []
        
        for i, news in enumerate(news_items):
            event = self._news_to_event(news, i, user_tags)
            if event:
                events.append(event)
        
        # æŒ‰åŒ¹é…åº¦æ’åº
        events.sort(key=lambda x: x.match_score, reverse=True)
        return events[:10]  # è¿”å›å‰10ä¸ªäº‹ä»¶
    
    def _news_to_event(self, news: NewsItem, index: int, user_tags: List[str] = None) -> Optional[GeneratedEvent]:
        """å°†æ–°é—»è½¬æ¢ä¸ºæ¸¸æˆäº‹ä»¶"""
        
        # åŸºäºæ–°é—»ç±»åˆ«ç”Ÿæˆäº‹ä»¶
        event_templates = {
            'policy': {
                'title_prefix': 'ğŸ“œ æ”¿ç­–é£å‘',
                'options': [
                    {'text': 'ç§¯æè°ƒæ•´æŠ•èµ„ç­–ç•¥åº”å¯¹æ”¿ç­–å˜åŒ–', 'tags': ['adaptive', 'risk_aware'], 'effects': {'happiness': 5}},
                    {'text': 'ä¿æŒè§‚æœ›ï¼Œç­‰å¾…æ›´æ˜ç¡®çš„ä¿¡å·', 'tags': ['conservative', 'patient'], 'effects': {}},
                    {'text': 'è¶æ”¿ç­–çª—å£æœŸå¸ƒå±€ç›¸å…³æ¿å—', 'tags': ['aggressive', 'opportunist'], 'effects': {'cash': -5000}},
                ]
            },
            'stock': {
                'title_prefix': 'ğŸ“ˆ è‚¡å¸‚å¿«è®¯',
                'options': [
                    {'text': 'è·Ÿéšå¸‚åœºè¶‹åŠ¿ï¼Œé€‚å½“åŠ ä»“', 'tags': ['trend_follower', 'aggressive'], 'effects': {'cash': -10000}},
                    {'text': 'è¶æœºè·åˆ©äº†ç»“ï¼Œè½è¢‹ä¸ºå®‰', 'tags': ['profit_taker', 'conservative'], 'effects': {'cash': 5000}},
                    {'text': 'æŒ‰å…µä¸åŠ¨ï¼ŒåšæŒé•¿æœŸæŒæœ‰', 'tags': ['steady', 'long_term'], 'effects': {}},
                ]
            },
            'crypto': {
                'title_prefix': 'â‚¿ åŠ å¯†åŠ¨æ€',
                'options': [
                    {'text': 'å°é¢ä¹°å…¥ï¼Œæ„Ÿå—å¸‚åœºè„‰æ', 'tags': ['crypto_curious', 'moderate'], 'effects': {'cash': -2000}},
                    {'text': 'é‡ä»“æŠ¼æ³¨ï¼Œæå–é«˜æ”¶ç›Š', 'tags': ['risk_taker', 'crypto_believer'], 'effects': {'cash': -20000}},
                    {'text': 'æ•¬è€Œè¿œä¹‹ï¼Œä¸“æ³¨ä¼ ç»ŸæŠ•èµ„', 'tags': ['conservative', 'traditional'], 'effects': {}},
                ]
            },
            'tech': {
                'title_prefix': 'ğŸ¤– ç§‘æŠ€å‰æ²¿',
                'options': [
                    {'text': 'æŠ•èµ„ç§‘æŠ€ETFï¼Œåˆ†äº«è¡Œä¸šçº¢åˆ©', 'tags': ['tech_investor', 'diversified'], 'effects': {'cash': -8000}},
                    {'text': 'ç²¾é€‰é¾™å¤´ä¸ªè‚¡ï¼Œé›†ä¸­æŠ•èµ„', 'tags': ['stock_picker', 'aggressive'], 'effects': {'cash': -15000}},
                    {'text': 'ä¿æŒå…³æ³¨ï¼Œæš‚ä¸ä»‹å…¥', 'tags': ['cautious', 'observer'], 'effects': {}},
                ]
            },
            'merger': {
                'title_prefix': 'ğŸ¤ å¹¶è´­é‡ç»„',
                'options': [
                    {'text': 'æŠ¼æ³¨å¹¶è´­æ¦‚å¿µè‚¡', 'tags': ['event_driven', 'speculator'], 'effects': {'cash': -10000}},
                    {'text': 'åˆ†æäº§ä¸šé“¾æœºä¼š', 'tags': ['analytical', 'value_investor'], 'effects': {'happiness': 3}},
                    {'text': 'è§„é¿ä¸ç¡®å®šæ€§é£é™©', 'tags': ['risk_averse', 'conservative'], 'effects': {}},
                ]
            },
            'global': {
                'title_prefix': 'ğŸŒ å…¨çƒè¦é—»',
                'options': [
                    {'text': 'é…ç½®æµ·å¤–èµ„äº§ï¼Œåˆ†æ•£é£é™©', 'tags': ['diversified', 'global_investor'], 'effects': {'cash': -8000}},
                    {'text': 'ä¸“æ³¨å›½å†…å¸‚åœºï¼Œæ·±è€•æœ¬åœŸ', 'tags': ['local_focused', 'conservative'], 'effects': {}},
                    {'text': 'åšå¥½æ±‡ç‡å¯¹å†²å‡†å¤‡', 'tags': ['hedger', 'risk_aware'], 'effects': {'cash': -3000}},
                ]
            },
            'macro': {
                'title_prefix': 'ğŸ“Š å®è§‚æ´å¯Ÿ',
                'options': [
                    {'text': 'é¡ºå‘¨æœŸè°ƒæ•´èµ„äº§é…ç½®', 'tags': ['adaptive', 'macro_aware'], 'effects': {}},
                    {'text': 'å¢åŠ ç°é‡‘å‚¨å¤‡ï¼Œä¿æŒçµæ´»', 'tags': ['conservative', 'cash_holder'], 'effects': {'cash': 2000}},
                    {'text': 'é€†å‘å¸ƒå±€ï¼Œå¯»æ‰¾é”™æ€æœºä¼š', 'tags': ['contrarian', 'value_hunter'], 'effects': {'cash': -5000}},
                ]
            }
        }
        
        template = event_templates.get(news.category, event_templates['macro'])
        
        # è®¡ç®—ä¸ç”¨æˆ·æ ‡ç­¾çš„åŒ¹é…åº¦
        match_score = 0.5  # åŸºç¡€åˆ†
        if user_tags:
            all_option_tags = []
            for opt in template['options']:
                all_option_tags.extend(opt.get('tags', []))
            
            matched = len(set(user_tags) & set(all_option_tags))
            match_score = 0.5 + (matched * 0.15)
        
        # æ ¹æ®æƒ…æ„Ÿè°ƒæ•´
        if news.sentiment == 'positive':
            match_score += 0.1
        elif news.sentiment == 'negative':
            match_score += 0.05  # è´Ÿé¢æ–°é—»ä¹Ÿæœ‰å‚è€ƒä»·å€¼
        
        # å¸‚åœºæƒ…ç»ªåŠ æˆ
        if self.market_sentiment == 'ç§¯æ':
            match_score += 0.05
        
        # çƒ­é—¨è¯é¢˜åŠ æˆ
        for topic in self.hot_topics[:5]:
            if topic.lower() in news.title_cn.lower() or topic.lower() in news.title.lower():
                match_score += 0.08
                break
        
        # æ„å»ºæè¿°
        description = f"ã€å®æ—¶èµ„è®¯ã€‘{news.title_cn}\n\n"
        description += f"æ¥æº: {news.source} | å¸‚åœºæƒ…ç»ª: {self.market_sentiment}\n\n"
        description += "è¿™æ¡æ¥è‡ªçœŸå®å¸‚åœºçš„æ¶ˆæ¯æ­£åœ¨å½±å“æŠ•èµ„è€…å†³ç­–ã€‚ä½ ä¼šå¦‚ä½•åº”å¯¹ï¼Ÿ"
        
        # AIåˆ†æ
        sentiment_map = {'positive': 'ä¹è§‚', 'negative': 'æ‚²è§‚', 'neutral': 'ä¸­æ€§'}
        ai_analysis = f"å½“å‰å¸‚åœºæ•´ä½“æƒ…ç»ª{self.market_sentiment}ï¼Œ"
        ai_analysis += f"æ­¤æ–°é—»å€¾å‘{sentiment_map.get(news.sentiment, 'ä¸­æ€§')}ã€‚"
        if self.hot_topics:
            ai_analysis += f" ä»Šæ—¥çƒ­ç‚¹: {', '.join(self.hot_topics[:3])}ã€‚"
        
        event = GeneratedEvent(
            id=f"news_{int(time.time())}_{index}",
            title=f"{template['title_prefix']}: {news.title_cn[:25]}...",
            description=description,
            category=news.category,
            tags=self._get_event_tags(news),
            options=template['options'],
            source_news=news.title_cn,
            ai_analysis=ai_analysis,
            match_score=min(match_score, 1.0),
            news_id=news.news_id
        )
        
        return event
    
    def _get_event_tags(self, news: NewsItem) -> List[str]:
        """ä¸ºäº‹ä»¶ç”Ÿæˆæ ‡ç­¾"""
        tags = [news.category]
        text = news.title_cn + news.title
        
        # åŸºäºå†…å®¹æ·»åŠ æ ‡ç­¾
        if any(k in text for k in ['åˆ©ç‡', 'å¤®è¡Œ', 'Fed', 'Federal Reserve', 'ç¾è”å‚¨']):
            tags.extend(['interest_rate', 'monetary_policy'])
        if any(k in text for k in ['è‚¡', 'stock', 'equity', 'S&P', 'Nasdaq']):
            tags.extend(['stock', 'equity'])
        if any(k in text for k in ['æ¯”ç‰¹å¸', 'åŠ å¯†', 'Bitcoin', 'crypto', 'BTC']):
            tags.extend(['crypto', 'digital_asset'])
        if any(k in text for k in ['é»„é‡‘', 'gold', 'Gold']):
            tags.extend(['gold', 'safe_haven'])
        if any(k in text for k in ['AI', 'äººå·¥æ™ºèƒ½', 'Nvidia', 'è‹±ä¼Ÿè¾¾', 'OpenAI']):
            tags.extend(['ai', 'tech_growth'])
        if any(k in text for k in ['æˆ¿', 'real estate', 'property']):
            tags.extend(['real_estate', 'property'])
        if any(k in text for k in ['å¹¶è´­', 'æ”¶è´­', 'merger', 'acquisition']):
            tags.extend(['merger', 'corporate_action'])
        if any(k in text for k in ['è´¢æŠ¥', 'earnings', 'revenue', 'è¥æ”¶']):
            tags.extend(['earnings', 'fundamental'])
            
        return list(set(tags))[:6]
    
    def get_market_status(self) -> Dict:
        """è·å–å½“å‰å¸‚åœºçŠ¶æ€æ‘˜è¦"""
        self.fetch_news()  # ç¡®ä¿æ•°æ®æ˜¯æœ€æ–°çš„
        return {
            'sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics[:10],
            'news_count': len(self.news_cache),
            'last_update': datetime.fromtimestamp(self.last_fetch).strftime('%Y-%m-%d %H:%M:%S') if self.last_fetch else None
        }
    
    def get_events_as_dict(self, user_tags: List[str] = None) -> List[Dict]:
        """è·å–äº‹ä»¶å­—å…¸åˆ—è¡¨ï¼ˆç”¨äºAPIè¿”å›ï¼‰- åŒæ­¥ç‰ˆæœ¬"""
        events = self.generate_events_from_news(user_tags)
        return [
            {
                'id': e.id,
                'title': e.title,
                'description': e.description,
                'category': e.category,
                'tags': e.tags,
                'options': e.options,
                'source_news': e.source_news,
                'ai_analysis': e.ai_analysis,
                'match_score': e.match_score,
                'is_real_news': True,
                'news_id': e.news_id
            }
            for e in events
        ]
    
    def get_db_events(self, user_tags: List[str] = None, limit: int = 20) -> List[Dict]:
        """ä»æ•°æ®åº“è·å–äº‹ä»¶"""
        if not self.db:
            return self.get_events_as_dict(user_tags)
        
        events = self.db.get_active_events(limit=limit)
        if not events:
            # æ•°æ®åº“ä¸ºç©ºï¼Œç”Ÿæˆæ–°äº‹ä»¶
            return self.sync_fetch_and_generate(user_tags, force_refresh=True)
        
        return self._filter_by_tags(events, user_tags)
    
    def get_event_stats(self) -> Dict:
        """è·å–äº‹ä»¶æ± ç»Ÿè®¡"""
        if self.db:
            return self.db.get_event_stats()
        return {
            'active_news': len(self.news_cache),
            'active_events': len(self.generated_events),
            'total_news': len(self.news_cache),
            'total_events': len(self.generated_events)
        }

# å…¨å±€å®ä¾‹
news_event_generator = NewsEventGenerator()
